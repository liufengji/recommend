2018-11-14 17:04:50,050   INFO --- [                                              main]  org.apache.spark.SparkContext                                                   (line:    54)  :  Running Spark version 2.1.1
2018-11-14 17:04:50,478   INFO --- [                                              main]  org.apache.spark.SecurityManager                                                (line:    54)  :  Changing view acls to: Administrator
2018-11-14 17:04:50,483   INFO --- [                                              main]  org.apache.spark.SecurityManager                                                (line:    54)  :  Changing modify acls to: Administrator
2018-11-14 17:04:50,488   INFO --- [                                              main]  org.apache.spark.SecurityManager                                                (line:    54)  :  Changing view acls groups to: 
2018-11-14 17:04:50,489   INFO --- [                                              main]  org.apache.spark.SecurityManager                                                (line:    54)  :  Changing modify acls groups to: 
2018-11-14 17:04:50,491   INFO --- [                                              main]  org.apache.spark.SecurityManager                                                (line:    54)  :  SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-11-14 17:04:51,227   INFO --- [                                              main]  org.apache.spark.util.Utils                                                     (line:    54)  :  Successfully started service 'sparkDriver' on port 1033.
2018-11-14 17:04:51,249   INFO --- [                                              main]  org.apache.spark.SparkEnv                                                       (line:    54)  :  Registering MapOutputTracker
2018-11-14 17:04:51,272   INFO --- [                                              main]  org.apache.spark.SparkEnv                                                       (line:    54)  :  Registering BlockManagerMaster
2018-11-14 17:04:51,278   INFO --- [                                              main]  org.apache.spark.storage.BlockManagerMasterEndpoint                             (line:    54)  :  Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-11-14 17:04:51,279   INFO --- [                                              main]  org.apache.spark.storage.BlockManagerMasterEndpoint                             (line:    54)  :  BlockManagerMasterEndpoint up
2018-11-14 17:04:51,292   INFO --- [                                              main]  org.apache.spark.storage.DiskBlockManager                                       (line:    54)  :  Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-45763d51-bb72-45fa-85cf-1af4ab883556
2018-11-14 17:04:51,315   INFO --- [                                              main]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  MemoryStore started with capacity 1977.9 MB
2018-11-14 17:04:51,397   INFO --- [                                              main]  org.apache.spark.SparkEnv                                                       (line:    54)  :  Registering OutputCommitCoordinator
2018-11-14 17:04:51,496   INFO --- [                                              main]  org.spark_project.jetty.util.log                                                (line:   186)  :  Logging initialized @2681ms
2018-11-14 17:04:51,612   INFO --- [                                              main]  org.spark_project.jetty.server.Server                                           (line:   327)  :  jetty-9.2.z-SNAPSHOT
2018-11-14 17:04:51,630   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@1d0d6318{/jobs,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,630   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@4bc28c33{/jobs/json,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,631   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@4409e975{/jobs/job,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,631   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@5c153b9e{/jobs/job/json,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,632   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@2a7686a7{/stages,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,632   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@758a34ce{/stages/json,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,633   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@7ec3394b{/stages/stage,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,633   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@bff34c6{/stages/stage/json,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,633   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@1522d8a0{/stages/pool,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,634   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@312ab28e{/stages/pool/json,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,634   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@5644dc81{/storage,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,634   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@246f8b8b{/storage/json,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,635   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@278bb07e{/storage/rdd,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,635   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@4351c8c3{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,635   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@3381b4fc{/environment,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,635   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@6bea52d4{/environment/json,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,636   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@11981797{/executors,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,636   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@5c42d2b7{/executors/json,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,636   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@625abb97{/executors/threadDump,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,637   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@5b1f29fa{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,644   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@aeab9a1{/static,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,644   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@40f70521{/,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,645   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@774698ab{/api,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,645   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@55342f40{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,646   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@a4ca3f6{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-11-14 17:04:51,689   INFO --- [                                              main]  org.spark_project.jetty.server.ServerConnector                                  (line:   266)  :  Started Spark@6aecbb8d{HTTP/1.1}{0.0.0.0:4040}
2018-11-14 17:04:51,690   INFO --- [                                              main]  org.spark_project.jetty.server.Server                                           (line:   379)  :  Started @2877ms
2018-11-14 17:04:51,691   INFO --- [                                              main]  org.apache.spark.util.Utils                                                     (line:    54)  :  Successfully started service 'SparkUI' on port 4040.
2018-11-14 17:04:51,694   INFO --- [                                              main]  org.apache.spark.ui.SparkUI                                                     (line:    54)  :  Bound SparkUI to 0.0.0.0, and started at http://169.254.13.102:4040
2018-11-14 17:04:51,786   INFO --- [                                              main]  org.apache.spark.executor.Executor                                              (line:    54)  :  Starting executor ID driver on host localhost
2018-11-14 17:04:51,977   INFO --- [                                              main]  org.apache.spark.util.Utils                                                     (line:    54)  :  Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 1078.
2018-11-14 17:04:51,977   INFO --- [                                              main]  org.apache.spark.network.netty.NettyBlockTransferService                        (line:    54)  :  Server created on 169.254.13.102:1078
2018-11-14 17:04:51,981   INFO --- [                                              main]  org.apache.spark.storage.BlockManager                                           (line:    54)  :  Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-11-14 17:04:51,982   INFO --- [                                              main]  org.apache.spark.storage.BlockManagerMaster                                     (line:    54)  :  Registering BlockManager BlockManagerId(driver, 169.254.13.102, 1078, None)
2018-11-14 17:04:51,985   INFO --- [                           dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerMasterEndpoint                             (line:    54)  :  Registering block manager 169.254.13.102:1078 with 1977.9 MB RAM, BlockManagerId(driver, 169.254.13.102, 1078, None)
2018-11-14 17:04:51,990   INFO --- [                                              main]  org.apache.spark.storage.BlockManagerMaster                                     (line:    54)  :  Registered BlockManager BlockManagerId(driver, 169.254.13.102, 1078, None)
2018-11-14 17:04:51,990   INFO --- [                                              main]  org.apache.spark.storage.BlockManager                                           (line:    54)  :  Initialized BlockManager: BlockManagerId(driver, 169.254.13.102, 1078, None)
2018-11-14 17:04:52,399   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@1df98368{/metrics/json,null,AVAILABLE,@Spark}
2018-11-14 17:04:52,607   INFO --- [                                              main]  org.apache.spark.sql.internal.SharedState                                       (line:    54)  :  Warehouse path is 'file:/E:/workspace/idea/jianshu/RecommendSystem/heihouzi/recommend/spark-warehouse/'.
2018-11-14 17:04:52,632   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@7dac3fd8{/SQL,null,AVAILABLE,@Spark}
2018-11-14 17:04:52,633   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@2102a4d5{/SQL/json,null,AVAILABLE,@Spark}
2018-11-14 17:04:52,636   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@6ce1f601{/SQL/execution,null,AVAILABLE,@Spark}
2018-11-14 17:04:52,638   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@1e886a5b{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-11-14 17:04:52,649   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   744)  :  Started o.s.j.s.ServletContextHandler@47747fb9{/static/sql,null,AVAILABLE,@Spark}
2018-11-14 17:04:54,121   INFO --- [                                              main]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 1977.8 MB)
2018-11-14 17:04:54,220   INFO --- [                                              main]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1977.8 MB)
2018-11-14 17:04:54,225   INFO --- [                           dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Added broadcast_0_piece0 in memory on 169.254.13.102:1078 (size: 14.3 KB, free: 1977.9 MB)
2018-11-14 17:04:54,232   INFO --- [                                              main]  org.apache.spark.SparkContext                                                   (line:    54)  :  Created broadcast 0 from textFile at DataLoader.scala:86
2018-11-14 17:04:54,344   INFO --- [                                              main]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_1 stored as values in memory (estimated size 127.1 KB, free 1977.6 MB)
2018-11-14 17:04:54,376   INFO --- [                                              main]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_1_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1977.6 MB)
2018-11-14 17:04:54,377   INFO --- [                           dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Added broadcast_1_piece0 in memory on 169.254.13.102:1078 (size: 14.3 KB, free: 1977.9 MB)
2018-11-14 17:04:54,380   INFO --- [                                              main]  org.apache.spark.SparkContext                                                   (line:    54)  :  Created broadcast 1 from textFile at DataLoader.scala:87
2018-11-14 17:04:54,400   INFO --- [                                              main]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_2 stored as values in memory (estimated size 127.1 KB, free 1977.5 MB)
2018-11-14 17:04:54,422   INFO --- [                                              main]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_2_piece0 stored as bytes in memory (estimated size 14.3 KB, free 1977.5 MB)
2018-11-14 17:04:54,425   INFO --- [                           dispatcher-event-loop-6]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Added broadcast_2_piece0 in memory on 169.254.13.102:1078 (size: 14.3 KB, free: 1977.9 MB)
2018-11-14 17:04:54,426   INFO --- [                                              main]  org.apache.spark.SparkContext                                                   (line:    54)  :  Created broadcast 2 from textFile at DataLoader.scala:88
2018-11-14 17:05:00,648   INFO --- [                                              main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator                 (line:    54)  :  Code generated in 459.934967 ms
2018-11-14 17:05:00,770   INFO --- [                                              main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator                 (line:    54)  :  Code generated in 31.394353 ms
2018-11-14 17:05:00,885   INFO --- [                                              main]  org.elasticsearch.hadoop.util.Version                                           (line:   108)  :  Elasticsearch Hadoop v5.6.2 [b71590160a]
2018-11-14 17:05:02,294   INFO --- [                                              main]  org.apache.hadoop.mapred.FileInputFormat                                        (line:   253)  :  Total input paths to process : 1
2018-11-14 17:05:02,342   INFO --- [                                              main]  org.apache.spark.SparkContext                                                   (line:    54)  :  Starting job: save at DataLoader.scala:134
2018-11-14 17:05:02,386   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Got job 0 (save at DataLoader.scala:134) with 2 output partitions
2018-11-14 17:05:02,388   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Final stage: ResultStage 0 (save at DataLoader.scala:134)
2018-11-14 17:05:02,391   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Parents of final stage: List()
2018-11-14 17:05:02,405   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Missing parents: List()
2018-11-14 17:05:02,428   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Submitting ResultStage 0 (MapPartitionsRDD[17] at save at DataLoader.scala:134), which has no missing parents
2018-11-14 17:05:02,637   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_3 stored as values in memory (estimated size 32.9 KB, free 1977.5 MB)
2018-11-14 17:05:02,644   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 1977.4 MB)
2018-11-14 17:05:02,646   INFO --- [                           dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Added broadcast_3_piece0 in memory on 169.254.13.102:1078 (size: 11.7 KB, free: 1977.8 MB)
2018-11-14 17:05:02,648   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.SparkContext                                                   (line:    54)  :  Created broadcast 3 from broadcast at DAGScheduler.scala:996
2018-11-14 17:05:02,670   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[17] at save at DataLoader.scala:134)
2018-11-14 17:05:02,676   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl                                    (line:    54)  :  Adding task set 0.0 with 2 tasks
2018-11-14 17:05:02,827   INFO --- [                           dispatcher-event-loop-1]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6112 bytes)
2018-11-14 17:05:02,835   INFO --- [                           dispatcher-event-loop-1]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 6112 bytes)
2018-11-14 17:05:02,862   INFO --- [            Executor task launch worker for task 0]  org.apache.spark.executor.Executor                                              (line:    54)  :  Running task 0.0 in stage 0.0 (TID 0)
2018-11-14 17:05:02,862   INFO --- [            Executor task launch worker for task 1]  org.apache.spark.executor.Executor                                              (line:    54)  :  Running task 1.0 in stage 0.0 (TID 1)
2018-11-14 17:05:03,017   INFO --- [            Executor task launch worker for task 1]  org.apache.spark.rdd.HadoopRDD                                                  (line:    54)  :  Input split: file:/E:/workspace/idea/jianshu/RecommendSystem/heihouzi/recommend/recommender/dataloader/src/main/resources/small/movies.csv:3300388+3300389
2018-11-14 17:05:03,017   INFO --- [            Executor task launch worker for task 0]  org.apache.spark.rdd.HadoopRDD                                                  (line:    54)  :  Input split: file:/E:/workspace/idea/jianshu/RecommendSystem/heihouzi/recommend/recommender/dataloader/src/main/resources/small/movies.csv:0+3300388
2018-11-14 17:05:03,040   INFO --- [            Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation                                (line:   840)  :  mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-11-14 17:05:03,040   INFO --- [            Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation                                (line:   840)  :  mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2018-11-14 17:05:03,041   INFO --- [            Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation                                (line:   840)  :  mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2018-11-14 17:05:03,042   INFO --- [            Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation                                (line:   840)  :  mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2018-11-14 17:05:03,042   INFO --- [            Executor task launch worker for task 1]  org.apache.hadoop.conf.Configuration.deprecation                                (line:   840)  :  mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2018-11-14 17:05:03,043   INFO --- [            Executor task launch worker for task 0]  org.apache.hadoop.conf.Configuration.deprecation                                (line:   840)  :  mapred.job.id is deprecated. Instead, use mapreduce.job.id
2018-11-14 17:05:04,016   INFO --- [            Executor task launch worker for task 0]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block rdd_11_0 stored as values in memory (estimated size 3.0 MB, free 1971.5 MB)
2018-11-14 17:05:04,016   INFO --- [            Executor task launch worker for task 1]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block rdd_11_1 stored as values in memory (estimated size 3.0 MB, free 1971.5 MB)
2018-11-14 17:05:04,022   INFO --- [                           dispatcher-event-loop-6]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Added rdd_11_0 in memory on 169.254.13.102:1078 (size: 3.0 MB, free: 1974.9 MB)
2018-11-14 17:05:04,023   INFO --- [                           dispatcher-event-loop-6]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Added rdd_11_1 in memory on 169.254.13.102:1078 (size: 3.0 MB, free: 1971.9 MB)
2018-11-14 17:05:04,049   INFO --- [            Executor task launch worker for task 0]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator                 (line:    54)  :  Code generated in 12.329009 ms
2018-11-14 17:05:04,143   INFO --- [            Executor task launch worker for task 0]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator                 (line:    54)  :  Code generated in 70.701883 ms
2018-11-14 17:05:04,239   INFO --- [            Executor task launch worker for task 0]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator                 (line:    54)  :  Code generated in 58.347591 ms
2018-11-14 17:05:12,183   INFO --- [            Executor task launch worker for task 1]  org.apache.spark.executor.Executor                                              (line:    54)  :  Finished task 1.0 in stage 0.0 (TID 1). 2332 bytes result sent to driver
2018-11-14 17:05:12,209   INFO --- [                              task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Finished task 1.0 in stage 0.0 (TID 1) in 9366 ms on localhost (executor driver) (1/2)
2018-11-14 17:05:12,423   INFO --- [            Executor task launch worker for task 0]  org.apache.spark.executor.Executor                                              (line:    54)  :  Finished task 0.0 in stage 0.0 (TID 0). 2245 bytes result sent to driver
2018-11-14 17:05:12,429   INFO --- [                              task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Finished task 0.0 in stage 0.0 (TID 0) in 9689 ms on localhost (executor driver) (2/2)
2018-11-14 17:05:12,434   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  ResultStage 0 (save at DataLoader.scala:134) finished in 9.727 s
2018-11-14 17:05:12,432   INFO --- [                              task-result-getter-1]  org.apache.spark.scheduler.TaskSchedulerImpl                                    (line:    54)  :  Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-11-14 17:05:12,449   INFO --- [                                              main]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Job 0 finished: save at DataLoader.scala:134, took 10.106160 s
2018-11-14 17:05:12,632   INFO --- [                                              main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator                 (line:    54)  :  Code generated in 38.646618 ms
2018-11-14 17:05:12,661   INFO --- [                                              main]  org.apache.hadoop.mapred.FileInputFormat                                        (line:   253)  :  Total input paths to process : 1
2018-11-14 17:05:12,669   INFO --- [                                              main]  org.apache.spark.SparkContext                                                   (line:    54)  :  Starting job: save at DataLoader.scala:144
2018-11-14 17:05:12,672   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Got job 1 (save at DataLoader.scala:144) with 2 output partitions
2018-11-14 17:05:12,672   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Final stage: ResultStage 1 (save at DataLoader.scala:144)
2018-11-14 17:05:12,673   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Parents of final stage: List()
2018-11-14 17:05:12,674   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Missing parents: List()
2018-11-14 17:05:12,677   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Submitting ResultStage 1 (MapPartitionsRDD[21] at save at DataLoader.scala:144), which has no missing parents
2018-11-14 17:05:12,709   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_4 stored as values in memory (estimated size 14.9 KB, free 1971.5 MB)
2018-11-14 17:05:12,718   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.2 KB, free 1971.5 MB)
2018-11-14 17:05:12,721   INFO --- [                           dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Added broadcast_4_piece0 in memory on 169.254.13.102:1078 (size: 7.2 KB, free: 1971.9 MB)
2018-11-14 17:05:12,722   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.SparkContext                                                   (line:    54)  :  Created broadcast 4 from broadcast at DAGScheduler.scala:996
2018-11-14 17:05:12,723   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[21] at save at DataLoader.scala:144)
2018-11-14 17:05:12,724   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl                                    (line:    54)  :  Adding task set 1.0 with 2 tasks
2018-11-14 17:05:12,728   INFO --- [                           dispatcher-event-loop-5]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 6113 bytes)
2018-11-14 17:05:12,730   INFO --- [                           dispatcher-event-loop-5]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 6113 bytes)
2018-11-14 17:05:12,731   INFO --- [            Executor task launch worker for task 3]  org.apache.spark.executor.Executor                                              (line:    54)  :  Running task 1.0 in stage 1.0 (TID 3)
2018-11-14 17:05:12,731   INFO --- [            Executor task launch worker for task 2]  org.apache.spark.executor.Executor                                              (line:    54)  :  Running task 0.0 in stage 1.0 (TID 2)
2018-11-14 17:05:12,750   INFO --- [            Executor task launch worker for task 2]  org.apache.spark.rdd.HadoopRDD                                                  (line:    54)  :  Input split: file:/E:/workspace/idea/jianshu/RecommendSystem/heihouzi/recommend/recommender/dataloader/src/main/resources/small/ratings.csv:0+1219116
2018-11-14 17:05:12,786   INFO --- [            Executor task launch worker for task 3]  org.apache.spark.rdd.HadoopRDD                                                  (line:    54)  :  Input split: file:/E:/workspace/idea/jianshu/RecommendSystem/heihouzi/recommend/recommender/dataloader/src/main/resources/small/ratings.csv:1219116+1219117
2018-11-14 17:05:12,812   INFO --- [            Executor task launch worker for task 2]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator                 (line:    54)  :  Code generated in 23.353574 ms
2018-11-14 17:05:23,809   INFO --- [                           dispatcher-event-loop-4]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Removed broadcast_3_piece0 on 169.254.13.102:1078 in memory (size: 11.7 KB, free: 1971.9 MB)
2018-11-14 17:06:10,741   INFO --- [            Executor task launch worker for task 3]  org.apache.spark.executor.Executor                                              (line:    54)  :  Finished task 1.0 in stage 1.0 (TID 3). 1464 bytes result sent to driver
2018-11-14 17:06:10,745   INFO --- [                              task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Finished task 1.0 in stage 1.0 (TID 3) in 58016 ms on localhost (executor driver) (1/2)
2018-11-14 17:06:11,234   INFO --- [            Executor task launch worker for task 2]  org.apache.spark.executor.Executor                                              (line:    54)  :  Finished task 0.0 in stage 1.0 (TID 2). 1464 bytes result sent to driver
2018-11-14 17:06:11,236   INFO --- [                              task-result-getter-3]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Finished task 0.0 in stage 1.0 (TID 2) in 58511 ms on localhost (executor driver) (2/2)
2018-11-14 17:06:11,238   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  ResultStage 1 (save at DataLoader.scala:144) finished in 58.512 s
2018-11-14 17:06:11,238   INFO --- [                              task-result-getter-3]  org.apache.spark.scheduler.TaskSchedulerImpl                                    (line:    54)  :  Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-11-14 17:06:11,240   INFO --- [                                              main]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Job 1 finished: save at DataLoader.scala:144, took 58.567187 s
2018-11-14 17:06:11,377   INFO --- [                                              main]  org.apache.hadoop.mapred.FileInputFormat                                        (line:   253)  :  Total input paths to process : 1
2018-11-14 17:06:11,388   INFO --- [                                              main]  org.apache.spark.SparkContext                                                   (line:    54)  :  Starting job: save at DataLoader.scala:154
2018-11-14 17:06:11,391   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Got job 2 (save at DataLoader.scala:154) with 2 output partitions
2018-11-14 17:06:11,392   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Final stage: ResultStage 2 (save at DataLoader.scala:154)
2018-11-14 17:06:11,397   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Parents of final stage: List()
2018-11-14 17:06:11,401   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Missing parents: List()
2018-11-14 17:06:11,402   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Submitting ResultStage 2 (MapPartitionsRDD[24] at save at DataLoader.scala:154), which has no missing parents
2018-11-14 17:06:11,414   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_5 stored as values in memory (estimated size 18.5 KB, free 1971.5 MB)
2018-11-14 17:06:11,419   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.5 KB, free 1971.5 MB)
2018-11-14 17:06:11,422   INFO --- [                           dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Added broadcast_5_piece0 in memory on 169.254.13.102:1078 (size: 8.5 KB, free: 1971.9 MB)
2018-11-14 17:06:11,423   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.SparkContext                                                   (line:    54)  :  Created broadcast 5 from broadcast at DAGScheduler.scala:996
2018-11-14 17:06:11,426   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[24] at save at DataLoader.scala:154)
2018-11-14 17:06:11,427   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl                                    (line:    54)  :  Adding task set 2.0 with 2 tasks
2018-11-14 17:06:11,431   INFO --- [                           dispatcher-event-loop-4]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 6110 bytes)
2018-11-14 17:06:11,434   INFO --- [                           dispatcher-event-loop-4]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Starting task 1.0 in stage 2.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 6110 bytes)
2018-11-14 17:06:11,436   INFO --- [            Executor task launch worker for task 5]  org.apache.spark.executor.Executor                                              (line:    54)  :  Running task 1.0 in stage 2.0 (TID 5)
2018-11-14 17:06:11,446   INFO --- [            Executor task launch worker for task 4]  org.apache.spark.executor.Executor                                              (line:    54)  :  Running task 0.0 in stage 2.0 (TID 4)
2018-11-14 17:06:11,454   INFO --- [            Executor task launch worker for task 5]  org.apache.spark.rdd.HadoopRDD                                                  (line:    54)  :  Input split: file:/E:/workspace/idea/jianshu/RecommendSystem/heihouzi/recommend/recommender/dataloader/src/main/resources/small/tags.csv:20903+20903
2018-11-14 17:06:11,463   INFO --- [            Executor task launch worker for task 4]  org.apache.spark.rdd.HadoopRDD                                                  (line:    54)  :  Input split: file:/E:/workspace/idea/jianshu/RecommendSystem/heihouzi/recommend/recommender/dataloader/src/main/resources/small/tags.csv:0+20903
2018-11-14 17:06:11,563   INFO --- [            Executor task launch worker for task 4]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block rdd_14_0 stored as values in memory (estimated size 14.0 KB, free 1971.5 MB)
2018-11-14 17:06:11,572   INFO --- [                           dispatcher-event-loop-1]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Added rdd_14_0 in memory on 169.254.13.102:1078 (size: 14.0 KB, free: 1971.9 MB)
2018-11-14 17:06:11,591   INFO --- [            Executor task launch worker for task 5]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block rdd_14_1 stored as values in memory (estimated size 12.5 KB, free 1971.5 MB)
2018-11-14 17:06:11,593   INFO --- [                           dispatcher-event-loop-3]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Added rdd_14_1 in memory on 169.254.13.102:1078 (size: 12.5 KB, free: 1971.9 MB)
2018-11-14 17:06:11,628   INFO --- [            Executor task launch worker for task 4]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator                 (line:    54)  :  Code generated in 51.840779 ms
2018-11-14 17:06:11,659   INFO --- [            Executor task launch worker for task 5]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator                 (line:    54)  :  Code generated in 24.385041 ms
2018-11-14 17:06:12,342   INFO --- [            Executor task launch worker for task 4]  org.apache.spark.executor.Executor                                              (line:    54)  :  Finished task 0.0 in stage 2.0 (TID 4). 2155 bytes result sent to driver
2018-11-14 17:06:12,344   INFO --- [                              task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Finished task 0.0 in stage 2.0 (TID 4) in 914 ms on localhost (executor driver) (1/2)
2018-11-14 17:06:12,354   INFO --- [            Executor task launch worker for task 5]  org.apache.spark.executor.Executor                                              (line:    54)  :  Finished task 1.0 in stage 2.0 (TID 5). 2245 bytes result sent to driver
2018-11-14 17:06:12,357   INFO --- [                              task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Finished task 1.0 in stage 2.0 (TID 5) in 926 ms on localhost (executor driver) (2/2)
2018-11-14 17:06:12,357   INFO --- [                              task-result-getter-1]  org.apache.spark.scheduler.TaskSchedulerImpl                                    (line:    54)  :  Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-11-14 17:06:12,357   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  ResultStage 2 (save at DataLoader.scala:154) finished in 0.929 s
2018-11-14 17:06:12,358   INFO --- [                                              main]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Job 2 finished: save at DataLoader.scala:154, took 0.969148 s
2018-11-14 17:06:18,371   INFO --- [                                              main]  org.elasticsearch.spark.sql.DataSource                                          (line:   503)  :  Overwriting data for recommend/movies
2018-11-14 17:06:18,979   INFO --- [                                              main]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator                 (line:    54)  :  Code generated in 66.104331 ms
2018-11-14 17:06:19,030   INFO --- [                                              main]  org.apache.spark.SparkContext                                                   (line:    54)  :  Starting job: runJob at EsSparkSQL.scala:97
2018-11-14 17:06:19,254   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Registering RDD 28 (map at DataLoader.scala:160)
2018-11-14 17:06:19,255   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Registering RDD 33 (map at DataLoader.scala:164)
2018-11-14 17:06:19,256   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Got job 3 (runJob at EsSparkSQL.scala:97) with 2 output partitions
2018-11-14 17:06:19,257   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Final stage: ResultStage 5 (runJob at EsSparkSQL.scala:97)
2018-11-14 17:06:19,257   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Parents of final stage: List(ShuffleMapStage 3, ShuffleMapStage 4)
2018-11-14 17:06:19,258   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Missing parents: List(ShuffleMapStage 3, ShuffleMapStage 4)
2018-11-14 17:06:19,265   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Submitting ShuffleMapStage 3 (MapPartitionsRDD[28] at map at DataLoader.scala:160), which has no missing parents
2018-11-14 17:06:19,291   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_6 stored as values in memory (estimated size 19.5 KB, free 1971.4 MB)
2018-11-14 17:06:19,296   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.4 KB, free 1971.4 MB)
2018-11-14 17:06:19,298   INFO --- [                           dispatcher-event-loop-0]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Added broadcast_6_piece0 in memory on 169.254.13.102:1078 (size: 8.4 KB, free: 1971.9 MB)
2018-11-14 17:06:19,299   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.SparkContext                                                   (line:    54)  :  Created broadcast 6 from broadcast at DAGScheduler.scala:996
2018-11-14 17:06:19,302   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Submitting 2 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[28] at map at DataLoader.scala:160)
2018-11-14 17:06:19,302   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl                                    (line:    54)  :  Adding task set 3.0 with 2 tasks
2018-11-14 17:06:19,308   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Submitting ShuffleMapStage 4 (MapPartitionsRDD[33] at map at DataLoader.scala:164), which has no missing parents
2018-11-14 17:06:19,313   INFO --- [                           dispatcher-event-loop-1]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5976 bytes)
2018-11-14 17:06:19,315   INFO --- [                           dispatcher-event-loop-1]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 5976 bytes)
2018-11-14 17:06:19,316   INFO --- [            Executor task launch worker for task 6]  org.apache.spark.executor.Executor                                              (line:    54)  :  Running task 0.0 in stage 3.0 (TID 6)
2018-11-14 17:06:19,323   INFO --- [            Executor task launch worker for task 7]  org.apache.spark.executor.Executor                                              (line:    54)  :  Running task 1.0 in stage 3.0 (TID 7)
2018-11-14 17:06:19,327   INFO --- [            Executor task launch worker for task 6]  org.apache.spark.storage.BlockManager                                           (line:    54)  :  Found block rdd_14_0 locally
2018-11-14 17:06:19,338   INFO --- [            Executor task launch worker for task 7]  org.apache.spark.storage.BlockManager                                           (line:    54)  :  Found block rdd_14_1 locally
2018-11-14 17:06:19,342   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_7 stored as values in memory (estimated size 32.4 KB, free 1971.4 MB)
2018-11-14 17:06:19,351   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_7_piece0 stored as bytes in memory (estimated size 11.1 KB, free 1971.4 MB)
2018-11-14 17:06:19,354   INFO --- [                           dispatcher-event-loop-5]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Added broadcast_7_piece0 in memory on 169.254.13.102:1078 (size: 11.1 KB, free: 1971.8 MB)
2018-11-14 17:06:19,355   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.SparkContext                                                   (line:    54)  :  Created broadcast 7 from broadcast at DAGScheduler.scala:996
2018-11-14 17:06:19,356   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[33] at map at DataLoader.scala:164)
2018-11-14 17:06:19,356   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl                                    (line:    54)  :  Adding task set 4.0 with 2 tasks
2018-11-14 17:06:19,366   INFO --- [                           dispatcher-event-loop-7]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Starting task 0.0 in stage 4.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5978 bytes)
2018-11-14 17:06:19,367   INFO --- [                           dispatcher-event-loop-7]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Starting task 1.0 in stage 4.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 5978 bytes)
2018-11-14 17:06:19,377   INFO --- [            Executor task launch worker for task 7]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator                 (line:    54)  :  Code generated in 14.856518 ms
2018-11-14 17:06:19,392   INFO --- [            Executor task launch worker for task 8]  org.apache.spark.executor.Executor                                              (line:    54)  :  Running task 0.0 in stage 4.0 (TID 8)
2018-11-14 17:06:19,392   INFO --- [            Executor task launch worker for task 9]  org.apache.spark.executor.Executor                                              (line:    54)  :  Running task 1.0 in stage 4.0 (TID 9)
2018-11-14 17:06:19,402   INFO --- [            Executor task launch worker for task 9]  org.apache.spark.storage.BlockManager                                           (line:    54)  :  Found block rdd_11_1 locally
2018-11-14 17:06:19,407   INFO --- [            Executor task launch worker for task 8]  org.apache.spark.storage.BlockManager                                           (line:    54)  :  Found block rdd_11_0 locally
2018-11-14 17:06:19,428   INFO --- [            Executor task launch worker for task 9]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator                 (line:    54)  :  Code generated in 21.743364 ms
2018-11-14 17:06:19,677   INFO --- [                             Spark Context Cleaner]  org.apache.spark.ContextCleaner                                                 (line:    54)  :  Cleaned accumulator 82
2018-11-14 17:06:19,684   INFO --- [                           dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Removed broadcast_5_piece0 on 169.254.13.102:1078 in memory (size: 8.5 KB, free: 1971.8 MB)
2018-11-14 17:06:19,685   INFO --- [                             Spark Context Cleaner]  org.apache.spark.ContextCleaner                                                 (line:    54)  :  Cleaned accumulator 83
2018-11-14 17:06:19,685   INFO --- [                             Spark Context Cleaner]  org.apache.spark.ContextCleaner                                                 (line:    54)  :  Cleaned accumulator 157
2018-11-14 17:06:19,697   INFO --- [                           dispatcher-event-loop-7]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Removed broadcast_4_piece0 on 169.254.13.102:1078 in memory (size: 7.2 KB, free: 1971.9 MB)
2018-11-14 17:06:19,728   INFO --- [            Executor task launch worker for task 6]  org.apache.spark.executor.Executor                                              (line:    54)  :  Finished task 0.0 in stage 3.0 (TID 6). 2258 bytes result sent to driver
2018-11-14 17:06:19,731   INFO --- [                              task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Finished task 0.0 in stage 3.0 (TID 6) in 423 ms on localhost (executor driver) (1/2)
2018-11-14 17:06:19,767   INFO --- [            Executor task launch worker for task 7]  org.apache.spark.executor.Executor                                              (line:    54)  :  Finished task 1.0 in stage 3.0 (TID 7). 2081 bytes result sent to driver
2018-11-14 17:06:19,769   INFO --- [                              task-result-getter-3]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Finished task 1.0 in stage 3.0 (TID 7) in 455 ms on localhost (executor driver) (2/2)
2018-11-14 17:06:19,769   INFO --- [                              task-result-getter-3]  org.apache.spark.scheduler.TaskSchedulerImpl                                    (line:    54)  :  Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-11-14 17:06:19,770   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  ShuffleMapStage 3 (map at DataLoader.scala:160) finished in 0.461 s
2018-11-14 17:06:19,771   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  looking for newly runnable stages
2018-11-14 17:06:19,772   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  running: Set(ShuffleMapStage 4)
2018-11-14 17:06:19,772   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  waiting: Set(ResultStage 5)
2018-11-14 17:06:19,773   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  failed: Set()
2018-11-14 17:06:19,825   INFO --- [            Executor task launch worker for task 8]  org.apache.spark.executor.Executor                                              (line:    54)  :  Finished task 0.0 in stage 4.0 (TID 8). 1926 bytes result sent to driver
2018-11-14 17:06:19,826   INFO --- [                              task-result-getter-0]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Finished task 0.0 in stage 4.0 (TID 8) in 462 ms on localhost (executor driver) (1/2)
2018-11-14 17:06:19,827   INFO --- [            Executor task launch worker for task 9]  org.apache.spark.executor.Executor                                              (line:    54)  :  Finished task 1.0 in stage 4.0 (TID 9). 1926 bytes result sent to driver
2018-11-14 17:06:19,828   INFO --- [                              task-result-getter-1]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Finished task 1.0 in stage 4.0 (TID 9) in 462 ms on localhost (executor driver) (2/2)
2018-11-14 17:06:19,828   INFO --- [                              task-result-getter-1]  org.apache.spark.scheduler.TaskSchedulerImpl                                    (line:    54)  :  Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-11-14 17:06:19,828   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  ShuffleMapStage 4 (map at DataLoader.scala:164) finished in 0.471 s
2018-11-14 17:06:19,828   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  looking for newly runnable stages
2018-11-14 17:06:19,828   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  running: Set()
2018-11-14 17:06:19,829   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  waiting: Set(ResultStage 5)
2018-11-14 17:06:19,829   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  failed: Set()
2018-11-14 17:06:19,829   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Submitting ResultStage 5 (MapPartitionsRDD[41] at rdd at EsSparkSQL.scala:97), which has no missing parents
2018-11-14 17:06:19,851   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_8 stored as values in memory (estimated size 30.5 KB, free 1971.4 MB)
2018-11-14 17:06:19,854   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  Block broadcast_8_piece0 stored as bytes in memory (estimated size 10.4 KB, free 1971.4 MB)
2018-11-14 17:06:19,855   INFO --- [                           dispatcher-event-loop-2]  org.apache.spark.storage.BlockManagerInfo                                       (line:    54)  :  Added broadcast_8_piece0 in memory on 169.254.13.102:1078 (size: 10.4 KB, free: 1971.8 MB)
2018-11-14 17:06:19,856   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.SparkContext                                                   (line:    54)  :  Created broadcast 8 from broadcast at DAGScheduler.scala:996
2018-11-14 17:06:19,857   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[41] at rdd at EsSparkSQL.scala:97)
2018-11-14 17:06:19,857   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.TaskSchedulerImpl                                    (line:    54)  :  Adding task set 5.0 with 2 tasks
2018-11-14 17:06:19,863   INFO --- [                           dispatcher-event-loop-5]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Starting task 0.0 in stage 5.0 (TID 10, localhost, executor driver, partition 0, ANY, 5883 bytes)
2018-11-14 17:06:19,865   INFO --- [                           dispatcher-event-loop-5]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Starting task 1.0 in stage 5.0 (TID 11, localhost, executor driver, partition 1, ANY, 5883 bytes)
2018-11-14 17:06:19,866   INFO --- [           Executor task launch worker for task 11]  org.apache.spark.executor.Executor                                              (line:    54)  :  Running task 1.0 in stage 5.0 (TID 11)
2018-11-14 17:06:19,866   INFO --- [           Executor task launch worker for task 10]  org.apache.spark.executor.Executor                                              (line:    54)  :  Running task 0.0 in stage 5.0 (TID 10)
2018-11-14 17:06:19,888   INFO --- [           Executor task launch worker for task 10]  org.apache.spark.storage.ShuffleBlockFetcherIterator                            (line:    54)  :  Getting 2 non-empty blocks out of 2 blocks
2018-11-14 17:06:19,888   INFO --- [           Executor task launch worker for task 11]  org.apache.spark.storage.ShuffleBlockFetcherIterator                            (line:    54)  :  Getting 2 non-empty blocks out of 2 blocks
2018-11-14 17:06:19,892   INFO --- [           Executor task launch worker for task 10]  org.apache.spark.storage.ShuffleBlockFetcherIterator                            (line:    54)  :  Started 0 remote fetches in 9 ms
2018-11-14 17:06:19,892   INFO --- [           Executor task launch worker for task 11]  org.apache.spark.storage.ShuffleBlockFetcherIterator                            (line:    54)  :  Started 0 remote fetches in 9 ms
2018-11-14 17:06:19,909   INFO --- [           Executor task launch worker for task 11]  org.apache.spark.storage.ShuffleBlockFetcherIterator                            (line:    54)  :  Getting 2 non-empty blocks out of 2 blocks
2018-11-14 17:06:19,909   INFO --- [           Executor task launch worker for task 10]  org.apache.spark.storage.ShuffleBlockFetcherIterator                            (line:    54)  :  Getting 2 non-empty blocks out of 2 blocks
2018-11-14 17:06:19,909   INFO --- [           Executor task launch worker for task 11]  org.apache.spark.storage.ShuffleBlockFetcherIterator                            (line:    54)  :  Started 0 remote fetches in 0 ms
2018-11-14 17:06:19,910   INFO --- [           Executor task launch worker for task 10]  org.apache.spark.storage.ShuffleBlockFetcherIterator                            (line:    54)  :  Started 0 remote fetches in 1 ms
2018-11-14 17:06:20,582   INFO --- [           Executor task launch worker for task 10]  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator                 (line:    54)  :  Code generated in 20.217695 ms
2018-11-14 17:06:20,626   INFO --- [           Executor task launch worker for task 11]  org.elasticsearch.spark.sql.EsDataFrameWriter                                   (line:   591)  :  Writing to [recommend/movies]
2018-11-14 17:06:20,626   INFO --- [           Executor task launch worker for task 10]  org.elasticsearch.spark.sql.EsDataFrameWriter                                   (line:   591)  :  Writing to [recommend/movies]
2018-11-14 17:06:25,621   INFO --- [           Executor task launch worker for task 11]  org.apache.spark.executor.Executor                                              (line:    54)  :  Finished task 1.0 in stage 5.0 (TID 11). 1938 bytes result sent to driver
2018-11-14 17:06:25,621   INFO --- [           Executor task launch worker for task 10]  org.apache.spark.executor.Executor                                              (line:    54)  :  Finished task 0.0 in stage 5.0 (TID 10). 1938 bytes result sent to driver
2018-11-14 17:06:25,622   INFO --- [                              task-result-getter-2]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Finished task 1.0 in stage 5.0 (TID 11) in 5758 ms on localhost (executor driver) (1/2)
2018-11-14 17:06:25,623   INFO --- [                              task-result-getter-3]  org.apache.spark.scheduler.TaskSetManager                                       (line:    54)  :  Finished task 0.0 in stage 5.0 (TID 10) in 5764 ms on localhost (executor driver) (2/2)
2018-11-14 17:06:25,623   INFO --- [                              task-result-getter-3]  org.apache.spark.scheduler.TaskSchedulerImpl                                    (line:    54)  :  Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-11-14 17:06:25,623   INFO --- [                          dag-scheduler-event-loop]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  ResultStage 5 (runJob at EsSparkSQL.scala:97) finished in 5.764 s
2018-11-14 17:06:25,623   INFO --- [                                              main]  org.apache.spark.scheduler.DAGScheduler                                         (line:    54)  :  Job 3 finished: runJob at EsSparkSQL.scala:97, took 6.592694 s
2018-11-14 17:06:25,629   INFO --- [                                              main]  org.apache.spark.rdd.MapPartitionsRDD                                           (line:    54)  :  Removing RDD 11 from persistence list
2018-11-14 17:06:25,633   INFO --- [           block-manager-slave-async-thread-pool-2]  org.apache.spark.storage.BlockManager                                           (line:    54)  :  Removing RDD 11
2018-11-14 17:06:25,639   INFO --- [                                              main]  org.apache.spark.rdd.MapPartitionsRDD                                           (line:    54)  :  Removing RDD 14 from persistence list
2018-11-14 17:06:25,640   INFO --- [           block-manager-slave-async-thread-pool-0]  org.apache.spark.storage.BlockManager                                           (line:    54)  :  Removing RDD 14
2018-11-14 17:06:25,646   INFO --- [                                              main]  org.spark_project.jetty.server.ServerConnector                                  (line:   306)  :  Stopped Spark@6aecbb8d{HTTP/1.1}{0.0.0.0:4040}
2018-11-14 17:06:25,648   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@a4ca3f6{/stages/stage/kill,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,649   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@55342f40{/jobs/job/kill,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,649   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@774698ab{/api,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,649   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@40f70521{/,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,649   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@aeab9a1{/static,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,649   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@5b1f29fa{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,649   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@625abb97{/executors/threadDump,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,650   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@5c42d2b7{/executors/json,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,650   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@11981797{/executors,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,650   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@6bea52d4{/environment/json,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,650   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@3381b4fc{/environment,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,650   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@4351c8c3{/storage/rdd/json,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,650   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@278bb07e{/storage/rdd,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,651   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@246f8b8b{/storage/json,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,651   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@5644dc81{/storage,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,651   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@312ab28e{/stages/pool/json,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,651   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@1522d8a0{/stages/pool,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,651   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@bff34c6{/stages/stage/json,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,651   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@7ec3394b{/stages/stage,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,651   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@758a34ce{/stages/json,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,652   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@2a7686a7{/stages,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,652   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@5c153b9e{/jobs/job/json,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,652   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@4409e975{/jobs/job,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,652   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@4bc28c33{/jobs/json,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,652   INFO --- [                                              main]  org.spark_project.jetty.server.handler.ContextHandler                           (line:   865)  :  Stopped o.s.j.s.ServletContextHandler@1d0d6318{/jobs,null,UNAVAILABLE,@Spark}
2018-11-14 17:06:25,654   INFO --- [                                              main]  org.apache.spark.ui.SparkUI                                                     (line:    54)  :  Stopped Spark web UI at http://169.254.13.102:4040
2018-11-14 17:06:25,665   INFO --- [                           dispatcher-event-loop-0]  org.apache.spark.MapOutputTrackerMasterEndpoint                                 (line:    54)  :  MapOutputTrackerMasterEndpoint stopped!
2018-11-14 17:06:25,686   INFO --- [                                              main]  org.apache.spark.storage.memory.MemoryStore                                     (line:    54)  :  MemoryStore cleared
2018-11-14 17:06:25,687   INFO --- [                                              main]  org.apache.spark.storage.BlockManager                                           (line:    54)  :  BlockManager stopped
2018-11-14 17:06:25,687   INFO --- [                                              main]  org.apache.spark.storage.BlockManagerMaster                                     (line:    54)  :  BlockManagerMaster stopped
2018-11-14 17:06:25,689   INFO --- [                           dispatcher-event-loop-2]  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint(line:    54)  :  OutputCommitCoordinator stopped!
2018-11-14 17:06:25,692   INFO --- [                                              main]  org.apache.spark.SparkContext                                                   (line:    54)  :  Successfully stopped SparkContext
2018-11-14 17:06:25,696   INFO --- [                                          Thread-1]  org.apache.spark.util.ShutdownHookManager                                       (line:    54)  :  Shutdown hook called
2018-11-14 17:06:25,697   INFO --- [                                          Thread-1]  org.apache.spark.util.ShutdownHookManager                                       (line:    54)  :  Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-b9fb8723-dc65-41f6-a122-7c3a0c178aee
